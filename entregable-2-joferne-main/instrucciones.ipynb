{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "instrucciones.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u82KjoFdi6aw"
      },
      "source": [
        "# Entregable 2: Construyendo un modelo de clasificación aplicando *fine-tuning*\n",
        "\n",
        "En este notebook se muestra cómo crear un modelo de clasificación de imágenes utilizando la técnica de *transfer-learning* conocida como *fine-tuning*.\n",
        "\n",
        "Para ello vamos a utilizar la librería [fastAI](https://www.fast.ai/). Este notebook está inspirado en el curso asociado a dicha librería. \n",
        "\n",
        "En esta práctica vamos a hacer un uso intensivo de la GPU, así que es importante activar su uso desde la opción *Notebook settings* del menú *Edit* . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRtSw3U8jhe9"
      },
      "source": [
        "## Carga de librerías\n",
        "\n",
        "Comenzamos instalando y cargando las librerías que vamos a necesitar en esta práctica. La librería ``fastai`` nos proporciona los distintos algoritmos de aprendizaje profundo y la librería ``os`` la utilizamos para la gestión de ficheros. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIuI4pB7MARV"
      },
      "source": [
        "!pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6CG1qo34ADz"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "import os\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z_ngcLujyST"
      },
      "source": [
        "## Creando nuestro dataset de imágenes\n",
        "\n",
        "El primer paso en cualquier proyecto de clasificación de imágenes es construir un dataset de imágenes anotadas. Aunque existen muchos datasets disponibles vamos a ver que con las técnicas explicadas en este notebook se pueden construir buenos modelos de clasificación para cualquier problema. \n",
        "\n",
        "En concreto, nuestro objetivo va a ser construir un modelo capaz de distinguir entre los personajes de la serie [Futurama](https://es.wikipedia.org/wiki/Futurama). En concreto queremos saber si quien aparece en una imagen es Fry, Bender o Leela. \n",
        "\n",
        "<img src=\"https://purepng.com/public/uploads/large/purepng.com-futurama-leela-fry-benderfuturamaanimationsciencefictioncartoonroberto-17015286039035k1si.png\" alt=\"Fry, Bender y Leela\" style=\"width: 50px;\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69cRT19Rk3iF"
      },
      "source": [
        "### Creando el dataset\n",
        "\n",
        "Para crear nuestro dataset vamos a utilizar imágenes adquiridas desde Google Imágenes. El proceso que seguimos para construir nuestro dataset viene explicado en el blog de [Adrian Rosebrock](https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/). En concreto hemos buscado imágenes de Fry, Leela y Bender y hemos creado los ficheros ``fry.csv``,  ``bender.csv`` y  ``leela.csv`` que contienen las URLs donde se encuentran las imágenes de cada uno de estos personajes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hzmfHM94unw"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ts1819/datasets/master/practica3/bender.csv -O bender.csv\n",
        "!wget https://raw.githubusercontent.com/ts1819/datasets/master/practica3/fry.csv -O fry.csv\n",
        "!wget https://raw.githubusercontent.com/ts1819/datasets/master/practica3/leela.csv -O leela.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuRvYNp4olcB"
      },
      "source": [
        "### Descargando las imágenes y organizando las carpetas\n",
        "\n",
        "Habitualmente para crear modelos de clasificación de imágenes se crea una carpeta para cada clase de imagen (en este caso necesitaremos crear tres carpetas, una para fry, otra para bender y otra para leela).\n",
        "\n",
        "En nuestro caso además de crear las carpetas debemos descargar las imágenes para ello debemos ejecutar las siguientes celdas (notad que el código es identico en los tres casos y lo único que cambia es la clase de las imágenes).\n",
        "\n",
        "Es posible que al intentar descargar alguna imagen se produzcan errores, pero no son relevantes (solo indican que esa imagen no se ha podido descargar).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVchUhZBMARY"
      },
      "source": [
        "path = Path('data/futurama')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhWMDDZd6YZV"
      },
      "source": [
        "folder = 'leela'\n",
        "file = 'leela.csv'\n",
        "dest = path/folder\n",
        "dest.mkdir(parents=True,exist_ok=True)\n",
        "os.rename(file,path/file)\n",
        "# Como mucho descargamos 200 imágenes\n",
        "download_images(dest,path/file,max_pics=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQQyb6rG8Rq7"
      },
      "source": [
        "folder = 'fry'\n",
        "file = 'fry.csv'\n",
        "dest = path/folder\n",
        "dest.mkdir(parents=True,exist_ok=True)\n",
        "os.rename(file,path/file)\n",
        "# Como mucho descargamos 200 imágenes\n",
        "download_images(dest,path/file,max_pics=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N2GyPvI6i79"
      },
      "source": [
        "folder = 'bender'\n",
        "file = 'bender.csv'\n",
        "dest = path/folder\n",
        "dest.mkdir(parents=True,exist_ok=True)\n",
        "os.rename(file,path/file)\n",
        "download_images(dest,path/file,max_pics=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogXtlXrQp4O8"
      },
      "source": [
        "Puede ocurrir que algunas imágenes tengan un formato que no pueda ser abierto por la librería, por lo que vamos a eliminarlas con la siguiente instrucción."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qToMjST6yCc"
      },
      "source": [
        "for im in verify_images(get_image_files(path)):\n",
        "    os.remove(str(im))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIHwkgGENbmi"
      },
      "source": [
        "A continuación vamos a partir nuestro dataset en un conjunto de entrenamiento y en otro de test (usaremos el 80% de las imágenes para entrenar y el 20% para test). Para partir el dataset debemos organizarlo con la siguiente estructura de directorios:\n",
        "\n",
        "```\n",
        "data\n",
        "└── futurama\n",
        "    ├── test\n",
        "    │   ├── bender\n",
        "    │   ├── fry\n",
        "    │   └── leela\n",
        "    └── train\n",
        "        ├── bender\n",
        "        ├── fry\n",
        "        └── leela\n",
        "```\n",
        "\n",
        "Es decir tenemos una carpeta train y otra carpeta test. Dentro de la carpeta train tendremos tantas carpetas como clases tiene nuestro dataset, y análogamente para la carpeta test. \n",
        "\n",
        "Comenzamos creando la estructura de carpetas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84NR_HANOq8N"
      },
      "source": [
        "(path/'train/bender').mkdir(parents=True,exist_ok=True)\n",
        "(path/'train/leela').mkdir(parents=True,exist_ok=True)\n",
        "(path/'train/fry').mkdir(parents=True,exist_ok=True)\n",
        "(path/'test/bender').mkdir(parents=True,exist_ok=True)\n",
        "(path/'test/leela').mkdir(parents=True,exist_ok=True)\n",
        "(path/'test/fry').mkdir(parents=True,exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32Ym4kO0PEy8"
      },
      "source": [
        "A continuación vamos a partir las imágenes descargadas previamente y las almacenamos en la carpeta correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe3kNkVCPEdM"
      },
      "source": [
        "trainBender, testBender = train_test_split(get_image_files(path/'bender'),test_size=0.2,random_state=15)\n",
        "trainLeela, testLeela = train_test_split(get_image_files(path/'leela'),test_size=0.2,random_state=15)\n",
        "trainFry, testFry = train_test_split(get_image_files(path/'fry'),test_size=0.2,random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXO-EE_0Poa7"
      },
      "source": [
        "for x in trainBender:\n",
        "  shutil.move(str(x),path/('train/bender/'+x.name))\n",
        "\n",
        "for x in trainLeela:\n",
        "  shutil.move(str(x),path/('train/leela/'+x.name))\n",
        "\n",
        "for x in trainFry:\n",
        "  shutil.move(str(x),path/('train/fry/'+x.name))\n",
        "\n",
        "for x in testBender:\n",
        "  shutil.move(str(x),path/('test/bender/'+x.name))\n",
        "\n",
        "for x in testLeela:\n",
        "  shutil.move(str(x),path/('test/leela/'+x.name))\n",
        "\n",
        "for x in testFry:\n",
        "  shutil.move(str(x),path/('test/fry/'+x.name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B_V2p9-Qciq"
      },
      "source": [
        "Por último eliminamos aquellas carpetas y ficheros que ya no vamos a utilizar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kDhiDp0QhJZ"
      },
      "source": [
        "shutil.rmtree('data/futurama/bender')\n",
        "shutil.rmtree('data/futurama/fry')\n",
        "shutil.rmtree('data/futurama/leela')\n",
        "os.remove('data/futurama/bender.csv')\n",
        "os.remove('data/futurama/fry.csv')\n",
        "os.remove('data/futurama/leela.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZ3jNlzqLso"
      },
      "source": [
        "### Cargando el dataset\n",
        "\n",
        "A continuación vamos a mostrar cómo se carga el dataset para poder posteriormente crear nuestro modelo. Este proceso se hace en dos pasos. Primero se construye un objeto `DataBlock` y a continuación se construye un objeto `DataLoader` a partir del `DataBlock`. Tienes más información sobre estos objetos en la documentación de [FastAI](https://docs.fast.ai/tutorial.datablock.html).\n",
        "\n",
        "### Datablock\n",
        "\n",
        "Comenzamos construyendo el objeto `DataBlock`. A continuación explicaremos cada una de sus componentes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4tmjAms60xE"
      },
      "source": [
        "db = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
        "                 get_items=get_image_files, \n",
        "                 splitter=RandomSplitter(valid_pct=0.2,seed=42),\n",
        "                 get_y=parent_label,\n",
        "                 item_tfms = Resize(512),\n",
        "                 batch_tfms=aug_transforms(size=256,min_scale=0.75))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6MrPGvtMARb"
      },
      "source": [
        "Vamos a ver las distintas componentes del `DataBlock`.\n",
        "\n",
        "- El atributo `blocks` sirve para indicar el tipo de nuestros datos. Como estamos en un problema de clasificación de imágenes, tenemos que la entrada de nuestro modelo será una imagen, es decir un `ImageBlock`, y la salida será una categoría, es decir un `CategoryBlock`. Por lo tanto indicamos que `blocks = (ImageBlock, CategoryBlock)`.\n",
        "- El atributo `get_items` debe proporcionar una función para leer los datos. En nuestro caso queremos leer una serie de imágenes que estarán almacenadas en un `path`. Para ello usamos la función `get_image_files`. Puedes ver qué hace exactamente esta función ejecutando el comando `??get_image_files`.\n",
        "- El atributo `splitter` nos indica cómo partir el dataset. Daros cuenta que tenemos un conjunto de entrenamiento y uno de test, pero para entrenar nuestro modelo y probar distintas alternativas nos interesa usar un conjunto de validación, que lo vamos a tomar de forma aleatorea a partir de nuestro conjunto de entrenamiento usando un 20% del mismo. Para ello usaremos el objeto `RandomSplitter(valid_pct=0.2,seed=42)`.\n",
        "- El atributo `get_y` sirve para indicar cómo extraemos la clase a partir de nuestros datos. La función `get_image_files` nos proporciona una lista con los paths a las imágenes de nuestro dataset. Si nos fijamos en dichos paths, la clase de cada imagen viene dada por la carpeta en la que está contenida, por lo que podemos usar el método `parent_label` para obtener la clase de la misma. \n",
        "\n",
        "Por último, los atributos `item_tfms` y `batch_tfms` sirven para aplicar una técnica conocida como *preescalado* (o *presizing*).   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgnjMPaGMARb"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "Pasamos ahora a construir nuestro `DataLoader` que se construye a partir del `DataBlock` construido anteriormente indicándole el path donde se encuentran nuestras imágenes. Además podemos configurar el `DataLoader` indicándole el tamaño del batch que queremos utilizar. Al trabajar con GPUs es importante que usemos batches de tamaño 2^n para optimizar el uso de la GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKTmcAvpRAV-"
      },
      "source": [
        "trainPath = Path('data/futurama/train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaCBj2DsMARd"
      },
      "source": [
        "dls = db.dataloaders(trainPath,bs=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL1_ynIGroiY"
      },
      "source": [
        "A continuación mostramos un batch de nuestro `DataLoader`. Es conveniente comprobar que realmente se han cargado las imágenes y sus anotaciones de manera correcta. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v9T5VnO7Qyp"
      },
      "source": [
        "dls.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tCsLWIqCB6R"
      },
      "source": [
        "## Creando el modelo de predicción\n",
        "\n",
        "A continuación vamos a crear nuestra red convolucional usando *transfer learning* y utilizando como base la arquitectura [ResNet 34](https://arxiv.org/abs/1512.03385); aunque existen otros [modelos disponibles](https://pytorch.org/docs/stable/torchvision/models.html) este modelo proporciona buenos resultados. Al crear nuestra red convolucional también debemos indicar la [métrica](https://docs.fast.ai/metrics.html#metrics) que vamos a utilizar para medir el rendimiento del modelo, en este caso vamos a usar el error_rate y la accuracy.\n",
        "\n",
        "La primera vez que se ejecuta la siguiente instrucción puede llevar algún tiempo debido a que se tienen que descargar los pesos asociados a la red ResNet 34. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G1r0BRO7mWv"
      },
      "source": [
        "learn = cnn_learner(dls,resnet18,metrics=accuracy).to_fp16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTpdSDLLDYwz"
      },
      "source": [
        "### Entrenando la red\n",
        "\n",
        "El siguiente paso es entrenar la red. Para ello vamos a utilizar el [siguiente procedimiento](https://sgugger.github.io/the-1cycle-policy.html) basado en la idea de fine-tuning:\n",
        "\n",
        "1. En primer lugar se dejan fijos (congelados) los pesos de la mayoría de capas de la red y sólo se actualizan los de las últimas capas. \n",
        "2. Se descongelan todas las capas de la red. \n",
        "3. Se reentrenan todas las capas de la red pero utilizando distintos *learning rates* en cada capa. \n",
        "\n",
        "La librería fastai proporciona toda la funcionalidad necesaria para llevar a cabo este proceso mediante el método `fine_tune`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ArmsuYMARf"
      },
      "source": [
        "learn.fine_tune(10,base_lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80e-nWMGMARf"
      },
      "source": [
        "Para su uso posterior, es conveniente exportar el modelo una vez entrenado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs3qvR6FMARf"
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdC4q7n6MARf"
      },
      "source": [
        "Podemos ver que dicho modelo se ha guardado en el mismo directorio donde nos encontramos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW94VSOzMARf"
      },
      "source": [
        "Path().ls(file_exts='.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ggAo4rKMts"
      },
      "source": [
        "## Interpretación de los resultados\n",
        "\n",
        "Vamos a interpretar los resultados utilizando la matriz de confusión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNGw0REMLhCj"
      },
      "source": [
        "A continuación se crear una interpretación de los resultados obtenidos con la misma. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntn2kVlR-2Yl"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXQUgCNSLmlb"
      },
      "source": [
        "Por último mostramos la matriz de confusión obtenida. Además de la matriz de confusión se puede obtener [otra información](https://docs.fast.ai/vision.learner.html#ClassificationInterpretation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEnhvKkr-7Md"
      },
      "source": [
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ-BfDvgL7Ir"
      },
      "source": [
        "Como podemos ver en la matriz de confusión anterior, el modelo tiende a confundir a Leela con Fry, esto puede deberse a que tengamos cierto ruido en nuestras imágenes (por ejemplo, imágenes que contengan a ambos personajes). Por lo tanto es conveniente limpiar nuestro dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZR_2M3aRv0S"
      },
      "source": [
        "### Evaluando el modelo en el conjunto de test\n",
        "\n",
        "Para poder evaluar nuestro modelo en el conjunto de test debemos crear un nuevo `DataBlock` y un nuevo `DataLoader`. La única diferencia con el `DataBlock` utilizado previamente es que para hacer la partición del dataset usamos un objeto de la clase `GrandparentSplitter` indicando que el conjunto de validación es nuestro conjunto de test. En el caso del `DataLoader`, la diferencia con el definido anteriormente es que cambiamos la ruta al path. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTkTCcBaRvQd"
      },
      "source": [
        "dbTest = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
        "                 get_items=get_image_files, \n",
        "                 splitter=GrandparentSplitter(valid_name='test'),\n",
        "                 get_y=parent_label,\n",
        "                 item_tfms = Resize(256),\n",
        "                 batch_tfms=aug_transforms(size=128,min_scale=0.75))\n",
        "dlsTest = dbTest.dataloaders(path,bs=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw6k9qkzR1Tx"
      },
      "source": [
        "Para trabajar con este dataloader debemos modificar nuestro objeto `Learner`. En concreto su atributo `dls`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um8thXI9R237"
      },
      "source": [
        "learn.dls = dlsTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsMV-Dv0R3ax"
      },
      "source": [
        "Ahora podemos evaluar nuestro modelo usando el método `validate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kj0-6GwR6Bd"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DM2lDFKR9Vf"
      },
      "source": [
        "El método `validate` nos devuelve dos valores: el valor de la función de pérdida, y el valor de nuestra métrica (la accuracy en este caso). Por lo que podemos ver que el modelo tiene una accuracy en el conjunto de test de aproximadamente un 71% (esto puede variar dependiendo de la ejecución). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbBhlCAfMOsn"
      },
      "source": [
        "## Limpiando el dataset\n",
        "\n",
        "Como hemos comentado anteriormente puede ocurrir que haya imágenes en nuestro dataset que no deberían estar ahí.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwW-Z3zY--hV"
      },
      "source": [
        "from fastai.vision.widgets import ImageClassifierCleaner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtqcQ7aTMe5m"
      },
      "source": [
        "En primer lugar podemos ver aquellas imágenes que tienen una mayor pérdida (es decir, aquellas que el modelo clasifica peor). Esto se puede hacer con ``.plot_top_losses``. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hBO55eQMeG_"
      },
      "source": [
        "interp.plot_top_losses(5,nrows=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdny5geBPuhs"
      },
      "source": [
        "A continuación podemos utilizar el siguiente widget para limpiar el dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iRK2IImOOz9"
      },
      "source": [
        "from fastai.vision.widgets import ImageClassifierCleaner\n",
        "cleaner = ImageClassifierCleaner(learn)\n",
        "cleaner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5WVagh-P4rD"
      },
      "source": [
        "Una vez que hayamos seleccionados para eliminar, podemos usar el siguiente comando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FxjhC9ZQLDS"
      },
      "source": [
        "for idx in cleaner.delete(): cleaner.fns[idx].unlink()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYDuA92oQTUJ"
      },
      "source": [
        "Como se puede apreciar hay ciertas imágenes en nuestro dataset que no son correctas, por lo que deberíamos hacer una limpieza del mismo para conseguir mejores resultados. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFeti_fWQujx"
      },
      "source": [
        "## Poniendo el modelo en producción\n",
        "\n",
        "Lo último que vamos a ver es cómo se puede poner el modelo en producción para usarlo para predecir la categoría de nuevas imágenes. \n",
        "\n",
        "Lo primero debemos exportar el modelo. La siguiente instrucción crea un fichero llamado 'export.pkl' en el directorio donde estamos trabajando (está almacenado en la variable ``path``) que sirve para desplegar el modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5yfOL5oQQyK"
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bl2ILd3R05Y"
      },
      "source": [
        "Podemos ver que se ha creado dicho fichero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2u7KG_-R47A"
      },
      "source": [
        "!ls data/futurama"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42FusvqaRCCb"
      },
      "source": [
        "A continuación indicamos al sistema que use la CPU para el proceso de inferncia (en caso de que el ordenador donde se despliega el modelo no tenga una GPU esto ocurre de manera automática)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tw57DxhRBPu"
      },
      "source": [
        "defaults.device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jegbF_0qRV7D"
      },
      "source": [
        "Vamos a probar nuestro modelo con una nueva imagen, en este caso de Fry. Comenzamos descargando dicha imagen, y a continuación la abrimos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX0zP2-CRVq1"
      },
      "source": [
        "!wget https://s.tcdn.co/802/3d8/8023d8dd-aada-3ff0-a91e-1c1b75b56a65/1.png -O fry.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQe2TMssRPIs"
      },
      "source": [
        "import PIL\n",
        "img = PILImage.create('fry.png')\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6wspuq5RkJy"
      },
      "source": [
        "A continuación creamos nuestro ``Learner``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwEySKpdRgqb"
      },
      "source": [
        "learn_inf = load_learner('export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_URhEs-kR90q"
      },
      "source": [
        "Y por último realizamos la predicción. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kdLeVcARpWa"
      },
      "source": [
        "pred_class,pred_idx,outputs=learn_inf.predict(img)\n",
        "pred_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhOQPl-XSM_T"
      },
      "source": [
        "La función `predict` devuelve tres valores:\n",
        "- La clase (buildings en este caso).\n",
        "- El índice asociado a dicha clase. \n",
        "- Las probabilidades para cada una de las categorías.  "
      ]
    }
  ]
}